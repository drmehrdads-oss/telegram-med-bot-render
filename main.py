import os
import io
import json
import logging
from typing import Optional

from fastapi import FastAPI, Request, Response

from telegram import Update
from telegram.ext import (
    Application,
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

from openai import OpenAI

# Optional PDF support (recommended)
# pip install pymupdf
try:
    import fitz  # PyMuPDF
except Exception:
    fitz = None  # type: ignore

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("medbot")


# ----------------------------
# ENV
# ----------------------------
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4.1-mini")  # vision+text capable
PUBLIC_URL = os.getenv("PUBLIC_URL")  # e.g. https://telegram-med-bot-render.onrender.com
WEBHOOK_SECRET = os.getenv("WEBHOOK_SECRET", "telegram-webhook")

if not TELEGRAM_TOKEN:
    raise RuntimeError("Missing TELEGRAM_BOT_TOKEN env var")
if not OPENAI_API_KEY:
    raise RuntimeError("Missing OPENAI_API_KEY env var")
if not PUBLIC_URL:
    raise RuntimeError("Missing PUBLIC_URL env var (your Render service URL)")

client = OpenAI(api_key=OPENAI_API_KEY)

app = FastAPI()
tg_app: Optional[Application] = None


# ----------------------------
# MEDICAL SYSTEM PROMPT (Persian)
# ----------------------------
SYSTEM_PROMPT_FA = """\
ØªÙˆ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø²Ø´Ú©ÛŒ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÛŒ (Ù¾Ø²Ø´Ú© Ù†ÛŒØ³ØªÛŒ).
ÙˆØ¸ÛŒÙÙ‡: Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø¹Ù„Ø§Ø¦Ù… Ú©Ø§Ø±Ø¨Ø±ØŒ 1) Ù‡Ø´Ø¯Ø§Ø± Ø§ÙˆØ±Ú˜Ø§Ù†Ø³ÛŒ Ø¨Ø¯Ù‡ Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø§Ø³ØªØŒ
2) Ú†Ù†Ø¯ Ø§Ø­ØªÙ…Ø§Ù„ Ú©Ù„ÛŒ Ø±Ø§ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡ (Ø¨Ø¯ÙˆÙ† ØªØ´Ø®ÛŒØµ Ù‚Ø·Ø¹ÛŒ)ØŒ
3) Ø¢Ø²Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ (Blood/Urine) Ùˆ ØªØµÙˆÛŒØ±Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ù…Ù†Ø§Ø³Ø¨ (X-ray/US/CT/MRI) Ø±Ø§ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø¯Ù‡
   Ùˆ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø¯Ø§Ù… ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡ Ø¨Ø¯Ù‡ Â«Ú†Ø±Ø§Â» Ùˆ Â«Ú†Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù„Ø§Ø²Ù… Ø§Ø³ØªÂ»ØŒ
4) Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ø³Ø§Ø¯Ù‡ Ùˆ Ø§ÛŒÙ…Ù† Ø¯Ø± Ø®Ø§Ù†Ù‡ (Ø§Ú¯Ø± Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª)ØŒ
5) Ú†Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø§ÛŒØ¯ Ù¾Ø²Ø´Ú©/Ø§ÙˆØ±Ú˜Ø§Ù†Ø³ Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†Ø¯.

Ù‚ÙˆØ§Ø¹Ø¯ Ø§ÛŒÙ…Ù†ÛŒ:
- Ù‡Ø±Ú¯Ø² Ø¯Ø§Ø±Ùˆ ØªØ¬ÙˆÛŒØ² Ù†Ú©Ù† (Ø¯ÙˆØ²/Ù†Ø§Ù… Ø¯Ø§Ø±ÙˆÛŒ Ù†Ø³Ø®Ù‡â€ŒØ§ÛŒ Ù†Ø¯Ù‡). ÙÙ‚Ø· ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ø§ÛŒÙ…Ù†.
- Ø§Ú¯Ø± Ø¹Ù„Ø§Ø¦Ù… Ø®Ø·Ø± (Ø¯Ø±Ø¯ Ù‚ÙØ³Ù‡ Ø³ÛŒÙ†Ù‡ØŒ ØªÙ†Ú¯ÛŒ Ù†ÙØ³ Ø´Ø¯ÛŒØ¯ØŒ Ø¶Ø¹Ù ÛŒÚ©Ø·Ø±ÙÙ‡ØŒ Ú¯ÛŒØ¬ÛŒØŒ Ø®ÙˆÙ†Ø±ÛŒØ²ÛŒ Ø´Ø¯ÛŒØ¯ØŒ ØºØ´ØŒ ØªØ¨ Ø¨Ø§Ù„Ø§ Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ø³ÙØªÛŒ Ú¯Ø±Ø¯Ù†...) ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯:
  ØªØ§Ú©ÛŒØ¯ Ú©Ù† Ú©Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ø§ÙˆØ±Ú˜Ø§Ù†Ø³ÛŒ Ø§Ø³Øª Ùˆ Ø¨Ø§ÛŒØ¯ ÙÙˆØ±Ø§Ù‹ Ø¨Ù‡ Ø§ÙˆØ±Ú˜Ø§Ù†Ø³/Ù¾Ø²Ø´Ú© Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†Ø¯.
- Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø¢Ø²Ù…Ø§ÛŒØ´/Ø¹Ú©Ø³ Ø§Ø±Ø³Ø§Ù„ Ú©Ø±Ø¯: ÙÙ‚Ø· ÛŒØ§ÙØªÙ‡â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ø·Ø¨ÛŒØ¹ÛŒ/Ù¾Ø±Ú†Ù… Ù‚Ø±Ù…Ø² Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù†ØŒ
  ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø²Ù…ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙØ³ÛŒØ± Ù¾Ø²Ø´Ú© Ø¯Ø§Ø±Ø¯.

Ù‚Ø§Ù„Ø¨ Ù¾Ø§Ø³Ø®:
- ğŸš¨ Ù‡Ø´Ø¯Ø§Ø± Ø§ÙˆØ±Ú˜Ø§Ù†Ø³ÛŒ (Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø§Ø³Øª)
- ğŸ” Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª (1-2 Ø®Ø·)
- ğŸ§ª Ø¢Ø²Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ
- ğŸ©» ØªØµÙˆÛŒØ±Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ
- âœ… Ú©Ø§Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ù„Ø§Ù† Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ù†Ø¬Ø§Ù… Ø¯Ø§Ø¯
- ğŸ§­ Ø³ÙˆØ§Ù„â€ŒÙ‡Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ÛŒ (Ø­Ø¯Ø§Ú©Ø«Ø± 5 Ø³ÙˆØ§Ù„)
"""


def _fa_intro() -> str:
    return (
        "Ø³Ù„Ø§Ù… ğŸ‘‹ Ù…Ù† Ø¯Ø³ØªÛŒØ§Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø²Ø´Ú©ÛŒ Ù‡Ø³ØªÙ… (Ù¾Ø²Ø´Ú© Ù†ÛŒØ³ØªÙ…).\n"
        "Ø¹Ù„Ø§Ø¦Ù…â€ŒØªØ§Ù† Ø±Ø§ + Ø³Ù† + Ø³Ø§Ø¨Ù‚Ù‡ Ø¨ÛŒÙ…Ø§Ø±ÛŒ/Ø¯Ø§Ø±ÙˆÙ‡Ø§ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯.\n"
        "Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù†ØªÛŒØ¬Ù‡ Ø¢Ø²Ù…Ø§ÛŒØ´ØŒ Ø¹Ú©Ø³ (JPEG/PNG) ÛŒØ§ PDF Ú¯Ø²Ø§Ø±Ø´ Ø±Ø§ Ù‡Ù… Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\n"
        "Ø§Ú¯Ø± ÙˆØ¶Ø¹ÛŒØª Ø§ÙˆØ±Ú˜Ø§Ù†Ø³ÛŒ Ø§Ø³Øª Ù‡Ù…ÛŒÙ† Ø§Ù„Ø§Ù† Ø¨Ø§ Ø§ÙˆØ±Ú˜Ø§Ù†Ø³ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯."
    )


# ----------------------------
# OpenAI helper
# ----------------------------
def openai_text_answer(user_text: str) -> str:
    resp = client.responses.create(
        model=OPENAI_MODEL,
        input=[
            {"role": "system", "content": SYSTEM_PROMPT_FA},
            {"role": "user", "content": user_text},
        ],
    )
    return resp.output_text.strip()


def openai_image_answer(user_text: str, image_bytes: bytes, mime: str) -> str:
    # OpenAI vision input
    resp = client.responses.create(
        model=OPENAI_MODEL,
        input=[
            {"role": "system", "content": SYSTEM_PROMPT_FA},
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": user_text},
                    {"type": "input_image", "image_data": image_bytes, "mime_type": mime},
                ],
            },
        ],
    )
    return resp.output_text.strip()


def extract_pdf_text(pdf_bytes: bytes) -> str:
    """
    Extract text from PDF. If fitz isn't installed or extraction fails, return "".
    """
    if fitz is None:
        return ""
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        parts = []
        for i in range(min(doc.page_count, 5)):  # first 5 pages is usually enough
            page = doc.load_page(i)
            t = page.get_text("text") or ""
            t = t.strip()
            if t:
                parts.append(f"[ØµÙØ­Ù‡ {i+1}]\n{t}")
        return "\n\n".join(parts).strip()
    except Exception as e:
        logger.exception("PDF text extraction failed: %s", e)
        return ""


def render_pdf_first_page_png(pdf_bytes: bytes) -> bytes:
    """
    Render first page of PDF to PNG (for scanned PDFs).
    """
    if fitz is None:
        return b""
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    page = doc.load_page(0)
    # Increase resolution a bit
    mat = fitz.Matrix(2, 2)
    pix = page.get_pixmap(matrix=mat)
    return pix.tobytes("png")


# ----------------------------
# Telegram handlers
# ----------------------------
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text(_fa_intro())


async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_text = (update.message.text or "").strip()
    if not user_text:
        return

    # Quick Persian instruction for "tests suggestion"
    # We let the model do the real work via the system prompt.
    answer = openai_text_answer(user_text)
    await update.message.reply_text(answer)


async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    # Get the highest resolution photo
    photos = update.message.photo or []
    if not photos:
        return
    photo = photos[-1]

    file = await context.bot.get_file(photo.file_id)
    bio = io.BytesIO()
    await file.download_to_memory(out=bio)
    image_bytes = bio.getvalue()

    caption = (update.message.caption or "").strip()
    user_text = (
        "Ø§ÛŒÙ† ÛŒÚ© ØªØµÙˆÛŒØ± Ø§Ø² Ù†ØªÛŒØ¬Ù‡ Ø¢Ø²Ù…Ø§ÛŒØ´/Ú¯Ø²Ø§Ø±Ø´/Ø¹Ú©Ø³ Ù¾Ø²Ø´Ú©ÛŒ Ø§Ø³Øª. "
        "Ù„Ø·ÙØ§Ù‹ Ù…ÙˆØ§Ø±Ø¯ ØºÛŒØ±Ø·Ø¨ÛŒØ¹ÛŒ ÛŒØ§ Ù¾Ø±Ú†Ù… Ù‚Ø±Ù…Ø² Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù† Ùˆ Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø§Ø³Øª Ø¢Ø²Ù…Ø§ÛŒØ´ ÛŒØ§ ØªØµÙˆÛŒØ±Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø¯Ù‡.\n"
        f"ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ø±Ø¨Ø±: {caption or 'Ù†Ø¯Ø§Ø±Ø¯'}"
    )

    answer = openai_image_answer(user_text, image_bytes=image_bytes, mime="image/jpeg")
    await update.message.reply_text(answer)


async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    doc = update.message.document
    if not doc:
        return

    # Allow PDFs and images in documents too
    mime = (doc.mime_type or "").lower()
    file = await context.bot.get_file(doc.file_id)
    bio = io.BytesIO()
    await file.download_to_memory(out=bio)
    data = bio.getvalue()

    caption = (update.message.caption or "").strip()

    # If PDF: try text extraction; if empty -> render first page -> vision
    if mime == "application/pdf" or (doc.file_name or "").lower().endswith(".pdf"):
        text = extract_pdf_text(data)
        if text:
            user_text = (
                "Ø§ÛŒÙ† Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ Ø§Ø² PDF Ú¯Ø²Ø§Ø±Ø´/Ø¢Ø²Ù…Ø§ÛŒØ´ Ø§Ø³Øª. "
                "ÙÙ‚Ø· Ù…ÙˆØ§Ø±Ø¯ ØºÛŒØ±Ø·Ø¨ÛŒØ¹ÛŒ ÛŒØ§ Ù…Ù‡Ù… Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù† Ùˆ Ø³Ù¾Ø³ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù„Ø§Ø¦Ù… Ø§Ø­ØªÙ…Ø§Ù„ÛŒØŒ Ø¢Ø²Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§ Ùˆ ØªØµÙˆÛŒØ±Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø±Ø§ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø¯Ù‡. "
                "Ø¯Ø§Ø±Ùˆ ØªØ¬ÙˆÛŒØ² Ù†Ú©Ù†.\n\n"
                f"ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ø±Ø¨Ø±: {caption or 'Ù†Ø¯Ø§Ø±Ø¯'}\n\n"
                f"Ù…ØªÙ† PDF:\n{text}"
            )
            answer = openai_text_answer(user_text)
            await update.message.reply_text(answer)
            return

        # scanned PDF fallback: render first page and use vision
        if fitz is None:
            await update.message.reply_text(
                "Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† PDF Ù„Ø§Ø²Ù… Ø§Ø³Øª Ø±ÙˆÛŒ Render Ù¾Ú©ÛŒØ¬ PyMuPDF Ù†ØµØ¨ Ø¨Ø§Ø´Ø¯ (pymupdf). "
                "ÙØ¹Ù„Ø§Ù‹ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù… PDF Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù†Ù…. Ù„Ø·ÙØ§Ù‹ Ø§Ø² Ù…Ø­ØªÙˆØ§ÛŒ Ú¯Ø²Ø§Ø±Ø´ Ø¹Ú©Ø³ ÙˆØ§Ø¶Ø­ (JPEG/PNG) Ø¨ÙØ±Ø³ØªÛŒØ¯."
            )
            return

        png = render_pdf_first_page_png(data)
        user_text = (
            "Ø§ÛŒÙ† ØªØµÙˆÛŒØ± ØµÙØ­Ù‡ Ø§ÙˆÙ„ PDF Ø§Ø³Øª (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø§Ø³Ú©Ù† Ø´Ø¯Ù‡). "
            "Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ†/Ø§Ø¹Ø¯Ø§Ø¯ Ø±Ø§ Ø¨Ø®ÙˆØ§Ù† Ùˆ Ù…ÙˆØ§Ø±Ø¯ ØºÛŒØ±Ø·Ø¨ÛŒØ¹ÛŒ ÛŒØ§ Ù…Ù‡Ù… Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù† Ùˆ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø¢Ø²Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§/ØªØµÙˆÛŒØ±Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø¯Ù‡. "
            "Ø¯Ø§Ø±Ùˆ ØªØ¬ÙˆÛŒØ² Ù†Ú©Ù†.\n"
            f"ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ø±Ø¨Ø±: {caption or 'Ù†Ø¯Ø§Ø±Ø¯'}"
        )
        answer = openai_image_answer(user_text, image_bytes=png, mime="image/png")
        await update.message.reply_text(answer)
        return

    # If image as a document (jpeg/png)
    if mime in ("image/jpeg", "image/png") or (doc.file_name or "").lower().endswith((".jpg", ".jpeg", ".png")):
        use_mime = "image/png" if mime == "image/png" or (doc.file_name or "").lower().endswith(".png") else "image/jpeg"
        user_text = (
            "Ø§ÛŒÙ† ÛŒÚ© ØªØµÙˆÛŒØ± Ø§Ø² Ù†ØªÛŒØ¬Ù‡ Ø¢Ø²Ù…Ø§ÛŒØ´/Ú¯Ø²Ø§Ø±Ø´/Ø¹Ú©Ø³ Ù¾Ø²Ø´Ú©ÛŒ Ø§Ø³Øª. "
            "Ù„Ø·ÙØ§Ù‹ Ù…ÙˆØ§Ø±Ø¯ ØºÛŒØ±Ø·Ø¨ÛŒØ¹ÛŒ ÛŒØ§ Ù¾Ø±Ú†Ù… Ù‚Ø±Ù…Ø² Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù† Ùˆ Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø§Ø³Øª Ø¢Ø²Ù…Ø§ÛŒØ´ ÛŒØ§ ØªØµÙˆÛŒØ±Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø¯Ù‡.\n"
            f"ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ø±Ø¨Ø±: {caption or 'Ù†Ø¯Ø§Ø±Ø¯'}"
        )
        answer = openai_image_answer(user_text, image_bytes=data, mime=use_mime)
        await update.message.reply_text(answer)
        return

    await update.message.reply_text(
        "ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· PDF Ùˆ Ø¹Ú©Ø³ (JPEG/PNG) Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù… Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†Ù…. "
        "Ø§Ú¯Ø± Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø§Ø±ÛŒØ¯ØŒ Ù„Ø·ÙØ§Ù‹ PDF ÛŒØ§ Ø¹Ú©Ø³ ÙˆØ§Ø¶Ø­ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯."
    )


# ----------------------------
# FastAPI webhook bridge
# ----------------------------
@app.get("/health")
async def health():
    return {"ok": True}


@app.post(f"/telegram/{WEBHOOK_SECRET}")
async def telegram_webhook(req: Request):
    if tg_app is None:
        return Response(status_code=503, content="Bot not ready")

    data = await req.json()
    update = Update.de_json(data, tg_app.bot)

    # Process update
    await tg_app.process_update(update)
    return {"ok": True}


@app.on_event("startup")
async def on_startup():
    global tg_app
    tg_app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    tg_app.add_handler(CommandHandler("start", cmd_start))
    tg_app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    tg_app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    tg_app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

    await tg_app.initialize()
    await tg_app.start()

    webhook_url = f"{PUBLIC_URL}/telegram/{WEBHOOK_SECRET}"
    await tg_app.bot.set_webhook(url=webhook_url)

    logger.info("Telegram webhook set to: %s", webhook_url)


@app.on_event("shutdown")
async def on_shutdown():
    global tg_app
    if tg_app is not None:
        await tg_app.stop()
        await tg_app.shutdown()
        tg_app = None
